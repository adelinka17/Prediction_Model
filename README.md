Project: Our team aimed to build a prediction model that analyzes how different features of Airbnb listings in NYC impact the daily price of an Airbnb rental. We used the following dataset (https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data). In this group project, we created a model that determines the price (target variable) based on input features such as location, room type, number of bedrooms, number of reviews, reviews per month, the number of listings on Airbnb by that specific host. Through Exploratory Data Analysis, we identified key factors that influence rental prices and tested different modeling techniques: linear regression, decision tree, random forest and ensemble models (which incorporates random forest and gradient boosting). The baseline model was linear regression. Among all tested models, the ensemble model yielded the best performance, achieving a test R^2 score of 0.634 and a test RMSE of 0.29. The evaluation metrics were R^2 score and RMSE.
Open Questions:
1) How would incorporating more dynamic features, such as real-time demand, seasonal variations affect the model’s accuracy compared to static features we investigated?
2) Can the model’s performance be significantly improved by utilizing more advanced machine learning techniques like neural networks?
3) Could decreasing the number of features through feature engineering, dimensionality reduction increase the accuracy compared to our current best result (63%)?
Extending it:
Given more time, extending the project to include neural networks for performance evaluation. Neural networks can capture complex nonlinear relationships, and do not require feature engineering. Additional experiments could be more comprehensive data preparation and feature engineering for the ensemble and decision tree models, evaluating if training on a smaller set of features(that contribute the most and have the higher weights) could potentially lead to better results.
Reflecting on the approach:
- Data Acquisition: Being more specific on the data source, the original dataset was found on
Kaggle, which was already structured and labeled (optimized for supervised learning), it did have some missing values and data preparation, standardization and normalization was necessary before the model training, however we had not used more current and other data sources: which could include information on reddit, twitter. Next steps could include potentially accessing Airbnb’s own dataset, and incorporating real-time data feeds, considering additional datasets from sources like http://insideairbnb.com/get-the-data/. As for Twitter, Reddit, potential extensions of the project could be around using sentiment analysis on the comments and reviews about popular listings and see if there is any correlation between this and the price of the listings.
- Thinking about the trade-off between model complexity and its performance. By using the Neural Network Regression model, we could feed into it all possible features of the current datasets(neighborhood popularity, property size and others), and it could learn the underlying patterns in the data. However,given the goals and relevance of the project, understanding that black-box nature of neural networks and their low interpretability could affect the model’s relevance. In addition it's important to take into account training time, costs and required resources (the constraints for the project). The training time for the Neural Network regression model is longer compared to models we used in our project. In addition, being able to understand how model arrived at the specific prediction is important for this type of dataset. Thus potentially experimenting with neural networks, while also analyzing how to improve the performance of the Ensemble Regression model (Boosted Decision Tree Regression), which has highest results, suitable for the problem (prediction of continuous variable-Regression), and has fast training tines.
